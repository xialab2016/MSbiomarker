---
title: "Manuscript_Code"
author: "Chenyi Chen"
date: "4/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# library 
```{r message=FALSE, warning=FALSE}
library(VennDiagram)
library(readr)
library(writexl) 
library(MASS) 
library(tidyr)
library(ggplot2)
library(pROC)
library(ROCR)
library(randomForest)
library(caTools)
library(caret)
library(glmnet)
library(corrplot)
library(plotmo) 
library(gplots) 
library(MLGL)
library(lmvar)
library(nnet)
library(grpreg)
library(gridExtra)
library(tableone)
library(dplyr)
library(xgboost)
library(psychometric)
library(e1071)
```


# read data 
```{r read data, warning=FALSE}
setwd("D:/Kay/MS_XiaLab/Oactive/File")
RM<- read_csv("RMMSClog220128.csv", col_types = cols(...1 = col_skip()))
Pitt1 <- read_csv("Pittlog_batch1.csv", col_types = cols(...1 = col_skip()))
Pitt2 <- read_csv("Pittlog_batch2.csv", col_types = cols(...1 = col_skip()))
# Pitt2 <- 
total_all_pitt <- read_csv("total_all_pitt.csv", 
    col_types = cols(serum_date = col_skip()))

Pitt2$id = Pitt2$id_participant

Pitt2= Pitt2[,c(2:ncol(Pitt2))]
Pitt2[,c(1:21)] = log(Pitt2[,c(1:21)])
Pitt2$cohort = 5
pitt = bind_rows(Pitt1, Pitt2)
pitt$pitt = 1
RM$pitt = 0
pitt = subset(pitt, select = -c(col4a1_abs,gh_abs) )
RM = subset(RM, select = -c(col4a1_abs,gh_abs) )
names(pitt) <- gsub("_abs", "", names(pitt))
names(RM) <- gsub("_abs", "", names(RM))
protein = toupper(c("aplp1", "ccl20", "cd6", "cdcp1", "cntn2", 
"cxcl13", "cxcl9", "flrt2", "gfap", 
"il12b", "mog", "nefl", "opg", "opn", "prtg", 
"serpina9", "tnfrsf10a", "tnfsf13b"
,"vcan"
))
names(pitt) <- c("id",protein,"Age", "pdds", "Sex", "dmt",
"Subtype" , "Disease_Duration", "PDDS_Time", 
"cohort", "pdds_cat", "Diagnose_Duration", "RaceEthnicity", "DMT_Efficacy", "pitt")

names(RM) <- c("id", "Age",  "Sex", "Disease_Duration", "pdds", toupper(c("opn", "cntn2", 
"serpina9", "prtg", "cxcl9", "cxcl13", "tnfsf13b", "cd6", "opg", 
"vcan", "tnfrsf10a", "il12b", "gfap", "mog", "cdcp1", "ccl20", 
"nefl", "flrt2", "aplp1")),"dmt", "PDDS_Time", "Subtype", 
"cohort", "pdds_cat", "Diagnose_Duration", "RaceEthnicity", "DMT_Efficacy", "pitt")
All_patients_none = bind_rows(pitt, RM)
All_patients_none = subset(All_patients_none, select = -c(Disease_Duration))

All_patients = 
  All_patients_none %>% filter(Diagnose_Duration<1000 & Subtype != 6) %>% left_join(total_all_pitt, by = c("id" = "id_participant") ) %>% rename( PROMIS= tscore, MSRSR = total, Disease_Duration = Diagnose_Duration, PROMIS_Time = PROMIS_duration)%>% mutate(pdds = ifelse(pdds == 7, 6, pdds),Subtype = ifelse(Subtype == 4 | Subtype == 5,1,0 ))

adjustVar = c( "Age", "Sex", "Subtype", 
"Disease_Duration", "RaceEthnicity", "DMT_Efficacy", "PDDS_Time")

# save(All_patients, file = "All_patients.RData")
# load("All_patients.RData")
```
# Patient Characteristics(Table 1)
```{r summary stats, warning= F}

remove = c("id",
           "dmt")
cor_df = All_patients[,(!names(All_patients) %in% remove)]
cor_df = cor_df %>% mutate(PROMIS_Bi  = ifelse(PROMIS<35,0,1) ) %>% dplyr::select(c(protein,"Age", "Sex", "Subtype", 
"Disease_Duration", "RaceEthnicity", "DMT_Efficacy", "PDDS_Time", 
"pdds", "pdds_cat", "PROMIS", "PROMIS_Bi", "PROMIS_Time","pitt")) 
var = c("Age", "Sex", "Subtype", 
"Disease_Duration", "RaceEthnicity", "DMT_Efficacy", "PDDS_Time", 
"pdds", "pdds_cat", "PROMIS", "PROMIS_Bi", "PROMIS_Time")
catVar = c( "pdds_cat","PROMIS_Bi", "Sex", "DMT_Efficacy", "Subtype", "RaceEthnicity")
summary_tbl = CreateTableOne(vars = var, strata = "pitt" , data = cor_df, factorVars = catVar)

```


# Feature Correlation(eFigure 2)
```{r correlation,warning=FALSE,fig.height=10.5, fig.width=9}

cor_df_plot = subset(cor_df, select = -c(PROMIS_Bi,pdds_cat,pitt) )
dput(names(cor_df_plot))

cor_df_plot = cor_df_plot %>% dplyr::select(c("APLP1", "CCL20", "CD6", "CDCP1", "CNTN2", "CXCL13", "CXCL9", 
"FLRT2", "GFAP", "IL12B", "MOG", "NEFL", "OPG", "OPN", "PRTG", 
"SERPINA9", "TNFRSF10A", "TNFSF13B", "VCAN", "Age", "Sex", "Subtype", 
"Disease_Duration", "RaceEthnicity", "DMT_Efficacy", "PDDS_Time","PROMIS_Time", 
"pdds", "PROMIS")) 
names(cor_df_plot) = c("APLP1", "CCL20", "CD6", "CDCP1", "CNTN2", "CXCL13", "CXCL9", 
"FLRT2", "GFAP", "IL12B", "MOG", "NEFL", "OPG", "OPN", "PRTG", 
"SERPINA9", "TNFRSF10A", "TNFSF13B", "VCAN", "Age", "Sex", "Subtype", 
"Disease Duration", "Race Ethnicity", "DMT Efficacy", "PDDS Time","PROMIS Time", 
"PDDS", "PROMIS")

M<-cor(cor_df_plot, use = "complete.obs",method = "spearman")
library(RColorBrewer)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)    
  p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
cor_allp = as.matrix(cor_df_plot)
p.mat <- cor.mtest(cor_allp)

svg("COR.svg",width = 10, height =11 )
corrplot(M, method="circle", col=col(200),
         number.cex= 17/ncol(M), #change the font size of number inside the cells
         type="lower",is.corr = FALSE,
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=90, #Text label color and rotation
         p.mat = p.mat, sig.level = 0.05, insig = "blank",
         diag=FALSE
         )
dev.off()

```
# Principal component analysis (eFigure 1)

```{r PCA plot}
pca.sample = All_patients[!duplicated(All_patients$id),]
pca.sample[,c(protein)]= scale(pca.sample[,c(protein)])
rownames(pca.sample) = pca.sample$id
pca.sample$pitt = as.factor(pca.sample$pitt)
pca.sample$cohort = as.factor(pca.sample$cohort)
pc <- prcomp(pca.sample[,c(protein)],
             center = T,
            scale. = F)
# plot(pc$x[,1], pc$x[,2])
pc.var = pc$sdev^2
pca.var.perc = round(pc.var/sum(pc.var)*100,1)
library(ggfortify)
library(factoextra)
svg("PCA.svg",width = 7, height = 5.2)
autoplot(pc, data=pca.sample, colour="cohort",frame=TRUE)
dev.off()
```
# ML Model Performance (Figure 2):
# LASSO regression model 
```{r build model for linear lasso }

eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))
  data.frame(
  RMSE = RMSE,
  Rsquare = R_square
)
  
}

attach_name = function (protein,adjustVar)
{
  if (!is.null(protein) & !is.null(adjustVar)){
    dataset = c("Protein & Clinical")
  }
    
    else{
      if ( !is.null(protein) & is.null(adjustVar) ){
        dataset = c("Protein Only")
      }
    
  else {
    if ( is.null(protein) & !is.null(adjustVar) ){
        dataset = c("Clinical Only")
      }
        }
    }
}
 
Build_LASSO_model = function(seed,ratio,protein,adjustVar,outcome,pitt,RM){
  set.seed(seed)
  if (!is.null(RM)){
  PITT =  pitt[complete.cases(pitt),c(protein,adjustVar,outcome)]
  RMM = RM[complete.cases(RM),c(protein,adjustVar,outcome)]
  
  p = (sample(nrow(PITT), nrow(PITT)*ratio))
  Rm = (sample(nrow(RMM), nrow(RMM)*ratio))
  
  p1 = PITT[p,]
  rm1 = RMM[Rm,]
  
  p2 = PITT[-p,]
  rm2 = RMM[-Rm,]
  
  train <-rbind(p1,rm1)
  test <-rbind(p2,rm2)
  }else
  {
    pitt =  All_patients[complete.cases(All_patients),c(protein,adjustVar,outcome)]
    dt = (sample(nrow(pitt), nrow(pitt)*ratio))
    train<-pitt[dt,]
    test<-pitt[-dt,]
  }
  y_train = as.numeric(unlist(train[,(names(train) %in% outcome)]))
  x <- data.matrix(train[,!(names(train) %in% outcome)])
  y_test = as.numeric(unlist(test[,(names(test) %in% outcome)]))
  x_test <- data.matrix(test[,!(names(test) %in% outcome)])
  lambdas <- 10^seq(2, -3, length = 500)
  cv_model <- cv.glmnet(x, y_train, alpha = 1,lambda = lambdas, standardize = TRUE,nfolds = 10)
  
  best_lambda <- cv_model$lambda.min
  
  best_model <- glmnet(x, y_train, alpha = 1, lambda = best_lambda)
  lasso.result.coef = as.data.frame(as.matrix(coef(best_model)))
  lasso.result.coef = lasso.result.coef[-1, , drop = F]
  lasso.result.coef = round(lasso.result.coef,6)
  predict(cv_model, s = "lambda.min", type = "coefficients")
  
  y_predicted_test <- predict(best_model, s = best_lambda, newx = x_test)
  eva = eval_results(y_test, y_predicted_test, test)
  ci = (as.numeric(CI.Rsq(eva$Rsquare,nrow(test),(ncol(test)-1))))
  
  r2ci = as.data.frame(c(paste(round(ci[1],2),"(",round(ci[3],2),",",round(ci[4],2),")")))
  feature_set = attach_name(protein,adjustVar)
  
  row.names(r2ci) = c(paste("R^2Ci",feature_set))
  names(r2ci) = c("Coefficient")
  names(lasso.result.coef) = c("Coefficient")
  
  Lasso_linear = rbind(r2ci,lasso.result.coef) 
  

}


```


## use continuous outcome with OLS LASSO regression 

### PDDS(eTable 4)

```{r}
seed = 2042
ratio =.8
protein_null = NULL
adjustVar_null = NULL
outcome = c("pdds")
LASSO_full_linear = Build_LASSO_model(seed,ratio,protein,adjustVar,outcome,pitt,RM)
LASSO_clnical_linear = Build_LASSO_model(seed,ratio,protein_null,adjustVar,outcome,pitt,RM)
LASSO_protein_linear = Build_LASSO_model(seed,ratio,protein,adjustVar_null,outcome,pitt,RM)

Lasso_linear_coef = rbind(LASSO_full_linear,LASSO_clnical_linear,LASSO_protein_linear)

```

### PROMIS(eTable 5)

```{r}
seed = 23
ratio =.8
protein_null = NULL
adjustVar_null = NULL
RM_null = NULL
outcome = c("PROMIS")
adjustVar.PROMIS = c( "Age", "Sex", "Subtype", 
"Disease_Duration", "RaceEthnicity", "DMT_Efficacy", "PROMIS_Time")

LASSO_full_linear = Build_LASSO_model(seed,ratio,protein,adjustVar.PROMIS,outcome,All_patients,RM_null)
LASSO_clnical_linear = Build_LASSO_model(seed,ratio,protein_null,adjustVar.PROMIS,outcome,All_patients,RM_null)
LASSO_protein_linear = Build_LASSO_model(seed,ratio,protein,adjustVar_null,outcome,All_patients,RM_null)

Lasso_linear_coef_PROMIS = rbind(LASSO_full_linear,LASSO_clnical_linear,LASSO_protein_linear)

```

## use binary outcome with LASSO regression 

model function: 
```{r}
LASSO.model =  function(seed,ratio,protein,adjustVar,outcome,pitt,RM,cutoff,run_comb){
# combined model --------------------------------
  set.seed(seed)
  if (!is.null(RM)){
  PITT =  pitt[complete.cases(pitt),c(protein,adjustVar,outcome)]
  RMM = RM[complete.cases(RM),c(protein,adjustVar,outcome)]
  
  p = (sample(nrow(PITT), nrow(PITT)*ratio))
  Rm = (sample(nrow(RMM), nrow(RMM)*ratio))
  
  p1 = PITT[p,]
  rm1 = RMM[Rm,]
  
  p2 = PITT[-p,]
  rm2 = RMM[-Rm,]
  
  train <-rbind(p1,rm1)
  test <-rbind(p2,rm2)
  }else
  {
    pitt =  pitt[complete.cases(pitt),c(protein,adjustVar,outcome)]
    dt = (sample(nrow(pitt), nrow(pitt)*ratio))
    train<-pitt[dt,]
    test<-pitt[-dt,]
  } 
  y_train = as.numeric(unlist(train[,(names(train) %in% outcome)]))
  x <- data.matrix(train[,!(names(train) %in% outcome)])
  y_test = as.numeric(unlist(test[,(names(test) %in% outcome)]))
  x_test <- data.matrix(test[,!(names(test) %in% outcome)])
  
  lambdas <- 10^seq(2, -3, length = 500)
  cv_model <- cv.glmnet(x, y_train, alpha = 1,lambda = lambdas, standardize = TRUE,nfolds = 10, type = "auc")
  
  best_lambda <- cv_model$lambda.min
  best_model <- glmnet(x, y_train, alpha = 1, lambda = best_lambda)
  lasso.result.coef = as.data.frame(as.matrix(coef(best_model)))
  lasso.result.coef = lasso.result.coef[-1, , drop = F]
  lasso.result.coef = round(lasso.result.coef,6)
    
  predictions_test <- predict(best_model, s = best_lambda, newx = x_test)
  
  new_pred_lasso = as.data.frame(ifelse(predictions_test >= cutoff, 1, 0))
  
  predictions_train <- predict(best_model, s = best_lambda, newx = x)
  
  data_lasso = cbind(test[,c(outcome)], new_pred_lasso)
  names(data_lasso) = c("actual", "pred")
  xtab_lasso = table(data_lasso$actual, data_lasso$pred)
  
  cm_lasso = confusionMatrix(xtab_lasso, mode = "everything", positive="1")
  F1Score = round(as.data.frame(cm_lasso$byClass[c(1,2:5,7)]),2)
  names(F1Score)= c("Coefficient")
  
  test$lasso.prob <- predict(best_model,type="response",newx = x_test, s = 'best_lambda')
  pred <- prediction(test$lasso.prob, test[, c(outcome)])
  auc = roc(y_test~ predictions_test)
  ci = as.numeric(ci.auc(auc))

  perf <- performance(pred,"tpr","fpr")
  auc11 = round(performance(pred,"auc")@y.values[[1]],2)
  auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
  names(auc1) = c("Coefficient")
  row.names(auc1) = c("CombinedCI")
  names(lasso.result.coef) = c("Coefficient")
  lasso.result.coef = rbind(auc1,F1Score,lasso.result.coef)
  if (run_comb == T){
# protein model --------------------------------
  set.seed(seed)
  if (!is.null(RM)){
  PITT =  pitt[complete.cases(pitt),c(protein,outcome)]
  RMM = RM[complete.cases(RM),c(protein,outcome)]
  
  p = (sample(nrow(PITT), nrow(PITT)*ratio))
  Rm = (sample(nrow(RMM), nrow(RMM)*ratio))
  
  p1 = PITT[p,]
  rm1 = RMM[Rm,]
  
  p2 = PITT[-p,]
  rm2 = RMM[-Rm,]
  
  train <-rbind(p1,rm1)
  test <-rbind(p2,rm2)
  }else
  {
    pitt =  All_patients[complete.cases(All_patients),c(protein,outcome)]
    dt = (sample(nrow(pitt), nrow(pitt)*ratio))
    train<-pitt[dt,]
    test<-pitt[-dt,]
  } 
  y_train = as.numeric(unlist(train[,(names(train) %in% outcome)]))
  x <- data.matrix(train[,!(names(train) %in% outcome)])
  y_test = as.numeric(unlist(test[,(names(test) %in% outcome)]))
  x_test <- data.matrix(test[,!(names(test) %in% outcome)])
  
  lambdas <- 10^seq(2, -3, length = 500)
  cv_model <- cv.glmnet(x, y_train, alpha = 1,lambda = lambdas, standardize = TRUE,nfolds = 10, type = "auc")
  
  best_lambda <- cv_model$lambda.min
  best_model <- glmnet(x, y_train, alpha = 1, lambda = best_lambda)
  lasso.result.coef3 = as.data.frame(as.matrix(coef(best_model)))
  lasso.result.coef3 = lasso.result.coef3[-1, , drop = F]
  lasso.result.coef3 = round(lasso.result.coef3,6)
    
  predictions_test <- predict(best_model, s = best_lambda, newx = x_test)
  
  new_pred_lasso = as.data.frame(ifelse(predictions_test >= cutoff, 1, 0))
  data_lasso = cbind(test[,c(outcome)], new_pred_lasso)
  names(data_lasso) = c("actual", "pred")
  xtab_lasso = table(data_lasso$actual, data_lasso$pred)
  
  cm_lasso = confusionMatrix(xtab_lasso, mode = "everything", positive="1")
  F1Score = round(as.data.frame(cm_lasso$byClass[c(1,2:5,7)]),2)
  names(F1Score)= c("Coefficient")
  
  test$lasso.prob <- predict(best_model,type="response",newx = x_test, s = 'best_lambda')
  pred <- prediction(test$lasso.prob, test[, c(outcome)])
  auc = roc(y_test~ predictions_test)
  ci = as.numeric(ci.auc(auc))
  perf3 <- performance(pred,"tpr","fpr")
  auc33 =  round(performance(pred,"auc")@y.values[[1]],2)
  auc3 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
  names(auc3) = c("Coefficient")
  row.names(auc3) = c("ProteinCI")
  names(lasso.result.coef3) = c("Coefficient")
  lasso.result.coef = rbind(lasso.result.coef,auc3,F1Score,lasso.result.coef3)
# Clinical model --------------------------------
  set.seed(seed)
  if (!is.null(RM)){
  PITT =  pitt[complete.cases(pitt),c(adjustVar,outcome)]
  RMM = RM[complete.cases(RM),c(adjustVar,outcome)]
  
  p = (sample(nrow(PITT), nrow(PITT)*ratio))
  Rm = (sample(nrow(RMM), nrow(RMM)*ratio))
  
  p1 = PITT[p,]
  rm1 = RMM[Rm,]
  
  p2 = PITT[-p,]
  rm2 = RMM[-Rm,]
  
  train <-rbind(p1,rm1)
  test <-rbind(p2,rm2)
  }else
  {
    pitt =  All_patients[complete.cases(All_patients),c(adjustVar,outcome)]
    dt = (sample(nrow(pitt), nrow(pitt)*ratio))
    train<-pitt[dt,]
    test<-pitt[-dt,]
  } 
  y_train = as.numeric(unlist(train[,(names(train) %in% outcome)]))
  x <- data.matrix(train[,!(names(train) %in% outcome)])
  y_test = as.numeric(unlist(test[,(names(test) %in% outcome)]))
  x_test <- data.matrix(test[,!(names(test) %in% outcome)])
  
  lambdas <- 10^seq(2, -3, length = 500)
  cv_model <- cv.glmnet(x, y_train, alpha = 1,lambda = lambdas, standardize = TRUE,nfolds = 10, type = "auc")
  
  best_lambda <- cv_model$lambda.min
  best_model <- glmnet(x, y_train, alpha = 1, lambda = best_lambda)
  lasso.result.coef2 = as.data.frame(as.matrix(coef(best_model)))
  lasso.result.coef2 = lasso.result.coef2[-1, , drop = F]
  lasso.result.coef2 = round(lasso.result.coef2,6)
    
  predictions_test <- predict(best_model, s = best_lambda, newx = x_test)
  
  new_pred_lasso = as.data.frame(ifelse(predictions_test >= cutoff, 1, 0))
  

  data_lasso = cbind(test[,c(outcome)], new_pred_lasso)
  names(data_lasso) = c("actual", "pred")
  xtab_lasso = table(data_lasso$actual, data_lasso$pred)
  
  cm_lasso = confusionMatrix(xtab_lasso, mode = "everything", positive="1")
  F1Score = round(as.data.frame(cm_lasso$byClass[c(1,2:5,7)]),2)
  names(F1Score)= c("Coefficient")
  
  test$lasso.prob <- predict(best_model,type="response",newx = x_test, s = 'best_lambda')
  pred <- prediction(test$lasso.prob, test[, c(outcome)])
  auc = roc(y_test~ predictions_test)
  ci = as.numeric(ci.auc(auc))
  perf2 <- performance(pred,"tpr","fpr")
  auc22 = round(performance(pred,"auc")@y.values[[1]],2)
  auc2 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
  names(auc2) = c("Coefficient")
  row.names(auc2) = c("ClinicalCI")
  
  names(lasso.result.coef2) = c("Coefficient")
  lasso.result.coef = rbind(lasso.result.coef,auc2,F1Score,lasso.result.coef2)
# plot ----------------
      svg(paste0("LASSO_",outcome,"_",seed,".svg"),width = 7, height = 5.2)
    {plot(perf3,colorize=FALSE, col="#0066CC")
    plot(perf2,colorize=FALSE, col="#990033",add = T) 
    plot(perf,colorize=FALSE, col="#FF9900",add = T) 
    lines(c(0,1),c(0,1),col = "gray", lty = 4 )
    legend(0.6,0.45, legend = c(paste("Serum Biomarker Profile (AUC =", auc33, ")"),
                                paste("Clinical Profile (AUC = ", auc22, ")"),
                      paste("Combined Profile (AUC = ", auc11, ")")),lty=c(1,1),lwd=c(1,1),col=c('#0066CC','#990033','#FF9900'),cex=.6)
    }
    dev.off()
    
        return(c(lasso.result.coef=lasso.result.coef, names = list(row.names(lasso.result.coef)), preds = as.data.frame(predictions_test), preds_train = as.data.frame(predictions_train) ))

  }
  else {
  return(lasso.result.coef)
  }

}

```

## PDDS(eTable 4)
```{r}
seed = 2042
ratio = 0.8
outcome = c("pdds_cat")
cutoff= 0.4
run_comb = T
LASSO =  LASSO.model(seed,ratio,protein,adjustVar,outcome,pitt,RM,cutoff,run_comb)
preds_lasso_test = LASSO$preds.s1
preds_lasso_train= LASSO$preds_train.s1

Lasso_Binary_coef_PDDS = LASSO$lasso.result.coef.Coefficient

Lasso_Binary_coef_PDDS = data.frame(LASSO$names,Lasso_Binary_coef_PDDS)

```

## PROMIS(eTable 5)

```{r}
seed = 23
RM_null = NULL
All_patients = All_patients %>% mutate(PROMIS_Bi  = ifelse(PROMIS<35,0,1) )

ratio = 0.8
outcome = c("PROMIS_Bi")
cutoff= 0.6
run_comb = T
Lasso_Binary_coef_PROMIS = LASSO.model(seed,ratio,protein,adjustVar.PROMIS,outcome,All_patients,RM_null,cutoff,run_comb)
preds_lasso_promis_train = Lasso_Binary_coef_PROMIS$preds_train.s1
preds_lasso_promis = Lasso_Binary_coef_PROMIS$preds.s1
Lasso_Binary_coef_PROMIS = data.frame(Lasso_Binary_coef_PROMIS$names,Lasso_Binary_coef_PROMIS$lasso.result.coef.Coefficient)
```

# Alternative machine learning models (eTable 6, eTable 7):
# Support Vector Machine (SVM)


```{r build svm mode, warning= F}

svm_model = function(seed,ratio,pitt,RM,protein,adjustVar,outcome,cutoff){
  
  
  set.seed(seed)
  if (!is.null(RM)){
  PITT =  pitt[complete.cases(pitt),c(protein,adjustVar,outcome)]
  RMM = RM[complete.cases(RM),c(protein,adjustVar,outcome)]
  
  p = (sample(nrow(PITT), nrow(PITT)*ratio))
  Rm = (sample(nrow(RMM), nrow(RMM)*ratio))
  
  p1 = PITT[p,]
  rm1 = RMM[Rm,]
  
  p2 = PITT[-p,]
  rm2 = RMM[-Rm,]
  
  train <-rbind(p1,rm1)
  test <-rbind(p2,rm2)
  }else
  {
    pitt =  All_patients[complete.cases(All_patients),c(protein,adjustVar,outcome)]
    dt = (sample(nrow(pitt), nrow(pitt)*ratio))
    train<-pitt[dt,]
    test<-pitt[-dt,]
  } 
  pitt = rbind(train,test)
  if (outcome == "pdds_cat"){
  pitt$pdds_cat = as.factor(pitt$pdds_cat)
  }  else {
  pitt$PROMIS_Bi= as.factor(pitt$PROMIS_Bi)
  }
  all_x <- data.matrix(pitt[,!(names(pitt) %in% outcome)])
  all_y = as.numeric(unlist(pitt[,(names(pitt) %in% outcome)]))
  Imp.svm <- rfe(all_x,all_y,
             sizes = c(5,
                         10,15,20,21,22,23,24,25,26),
                       
             rfeControl = rfeControl(functions = caretFuncs,
                                     verbose = FALSE,number = 5),
                               method = "svmRadial")
  feature = as.data.frame(predictors(Imp.svm))
  y_train = as.numeric(unlist(train[,(names(train) %in% outcome)]))
  x <- data.matrix(train[,!(names(train) %in% outcome)])
  y_test = as.numeric(unlist(test[,(names(test) %in% outcome)]))
  x_test <- data.matrix(test[,!(names(test) %in% outcome)])
  model_svm = svm(y_train ~ .,
                 data = train,
                 cost = 10,scale = T,
                 kernel = 'radial')
  set.seed(seed)
  if (outcome == "pdds_cat"){
    tmodel=tune(svm,pdds_cat ~., data=train,
  ranges=list(cost = c(0.001, 0.01, 0.1, 1,5,10,15)))
  best_model = tmodel$best.model
  }  else {
    tmodel=tune(svm,PROMIS_Bi ~., data=train,
  ranges=list(cost = c(0.001, 0.01, 0.1, 1,5,10,15)))
  best_model = tmodel$best.model
  }
  
  pred <- predict(best_model, x_test, type="prob")
  new_pred_svm = as.data.frame(ifelse(pred >= cutoff, 1, 0))  
  
  pred_train <- predict(best_model, x, type="prob")
  new_pred_svm_train = as.data.frame(ifelse(pred_train >= cutoff, 1, 0))
  
  data_svm = cbind(test[,c(outcome)], new_pred_svm)
  names(data_svm) = c("actual", "pred")
  xtab_svm = table(data_svm$actual, data_svm$pred)
    
  cm_svm = confusionMatrix(xtab_svm, mode = "everything", positive="1")
  F1Score = round(as.data.frame(cm_svm$byClass[c(1,2:5,7)]),2)
  names(F1Score)= c("Coefficient")

  # Model Performance Statistics
  pred_val <-prediction(pred, y_test)
  auc = roc(y_test~ pred)
  ci = as.numeric(ci.auc(auc))
  auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
  names(auc1) = c("Coefficient")
  row.names(auc1) = c("Combined")

  # Calculating Area under Curve
  perf_val <- performance(pred_val,"auc")
  perf_val
  # Calculating True Positive and False Positive Rate
  perf_1 <- performance(pred_val, "tpr", "fpr")
  auc11 = round(perf_val@y.values[[1]],2)
  # Plot the ROC curve
  plot(perf_1, col = "green", lwd = 1.5)
  svm_coef = rbind(F1Score,auc1)
  return (c(performance = svm_coef, coefficient = feature, perf = perf_1, confusionMat = cm_svm, preds = as.data.frame(pred), preds_train = as.data.frame(pred_train)))
}
  
```

## PDDS 
```{r run PDDS svm model,warning = F, message = F}
outcome = c("pdds_cat")
seed = 2042
ratio = 0.8
cutoff = 0.25
SVM_PDDS_combine = svm_model(seed,ratio,pitt,RM,protein,adjustVar,outcome,cutoff)
auc11 = as.numeric(substr(SVM_PDDS_combine$performance.Coefficient[7],1,4))
perf = SVM_PDDS_combine$perf
SVM_PDDS_combine_perf = as.data.frame((SVM_PDDS_combine$performance.Coefficient))
row.names(SVM_PDDS_combine_perf) = c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI")
names(SVM_PDDS_combine_perf) = c("Coef")
SVM_PDDS_Feature = SVM_PDDS_combine$`coefficient.predictors(Imp.svm)`

pred_SVM = SVM_PDDS_combine$preds.pred
pred_SVM_train = SVM_PDDS_combine$preds_train


SVM_PDDS_protein = svm_model(seed,ratio,pitt,RM,protein,adjustVar_null,outcome,cutoff)
auc33 = as.numeric(substr(SVM_PDDS_protein$performance.Coefficient[7],1,4))
perf3 = SVM_PDDS_protein$perf
SVM_PDDS_protein_perf = as.data.frame(SVM_PDDS_protein$performance.Coefficient)
row.names(SVM_PDDS_protein_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_protein")
names(SVM_PDDS_protein_perf) = c("Coef")
  
SVM_PDDS_clinical = svm_model(seed,ratio,pitt,RM,protein_null,adjustVar,outcome,cutoff)
perf2 = SVM_PDDS_clinical$perf
auc22 = as.numeric(substr(SVM_PDDS_clinical$performance.Coefficient[7],1,4))
SVM_PDDS_clinical_perf = as.data.frame(SVM_PDDS_clinical$performance.Coefficient)
row.names(SVM_PDDS_clinical_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_Clinical")
names(SVM_PDDS_clinical_perf) = c("Coef")

SVM_PDDS_total = rbind(SVM_PDDS_combine_perf,SVM_PDDS_protein_perf,SVM_PDDS_clinical_perf)
svg("SVM_PDDS_2042.svg",width = 7, height = 5.2)
{plot(perf3,colorize=FALSE, col="#0066CC")
plot(perf2,colorize=FALSE, col="#990033",add = T) 
plot(perf,colorize=FALSE, col="#FF9900",add = T) 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend(0.6,0.45, legend = c(paste("Serum Biomarker Profile (AUC =", auc33, ")"),
                          paste("Clinical Profile (AUC = ", auc22, ")"),
                paste("Combined Profile (AUC = ", auc11, ")")),lty=c(1,1),lwd=c(1,1),col=c('#0066CC','#990033','#FF9900'),cex=.6)
}
dev.off()
```

## PROMIS
```{r run PROMIS svm model,warning = F, message = F}
outcome = c("PROMIS_Bi")
seed = 23
ratio = 0.8
cutoff = 0.7

SVM_PROMIS_combine = svm_model(seed,ratio,All_patients,RM_null,protein,adjustVar.PROMIS,outcome,cutoff)
auc11 = as.numeric(substr(SVM_PROMIS_combine$performance.Coefficient[7],1,4))
perf = SVM_PROMIS_combine$perf
pred_SVM_PROMIS = SVM_PROMIS_combine$preds.pred
pred_SVM_PROMIS_train = SVM_PROMIS_combine$preds_train.pred_train

SVM_PROMIS_combine_perf = as.data.frame((SVM_PROMIS_combine$performance.Coefficient))
row.names(SVM_PROMIS_combine_perf) = c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI")
names(SVM_PROMIS_combine_perf) = c("Coef")
SVM_PROMIS_Feature = SVM_PROMIS_combine$`coefficient.predictors(Imp.svm)`
SVM_PROMIS_combine$confusionMat.table
SVM_PROMIS_protein = svm_model(seed,ratio,All_patients,RM_null,protein,adjustVar_null,outcome,cutoff)
auc33 = as.numeric(substr(SVM_PROMIS_protein$performance.Coefficient[7],1,4))
perf3 = SVM_PROMIS_protein$perf
SVM_PROMIS_protein_perf = as.data.frame(SVM_PROMIS_protein$performance.Coefficient)
row.names(SVM_PROMIS_protein_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_protein")
names(SVM_PROMIS_protein_perf) = c("Coef")
SVM_PROMIS_protein$confusionMat.table

SVM_PROMIS_clinical = svm_model(seed,ratio,All_patients,RM_null,protein_null,adjustVar.PROMIS,outcome,cutoff)
perf2 = SVM_PROMIS_clinical$perf
auc22 = as.numeric(substr(SVM_PROMIS_clinical$performance.Coefficient[7],1,4))
SVM_PROMIS_clinical_perf = as.data.frame(SVM_PROMIS_clinical$performance.Coefficient)
row.names(SVM_PROMIS_clinical_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_Clinical")
names(SVM_PROMIS_clinical_perf) = c("Coef")

SVM_PROMIS_total = rbind(SVM_PROMIS_combine_perf,SVM_PROMIS_protein_perf,SVM_PROMIS_clinical_perf)
svg("SVM_PROMIS_23.svg",width = 7, height = 5.2)
{plot(perf3,colorize=FALSE, col="#0066CC")
plot(perf2,colorize=FALSE, col="#990033",add = T) 
plot(perf,colorize=FALSE, col="#FF9900",add = T) 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend(0.6,0.45, legend = c(paste("Serum Biomarker Profile (AUC =", auc33, ")"),
                          paste("Clinical Profile (AUC = ", auc22, ")"),
                paste("Combined Profile (AUC = ", auc11, ")")),lty=c(1,1),lwd=c(1,1),col=c('#0066CC','#990033','#FF9900'),cex=.6)
}
dev.off()
```


# XGBoost

```{r}

xgb_model = function(seed,ratio,pitt,RM,protein,adjustVar,outcome,cutoff){
  
  
  set.seed(seed)
  if (!is.null(RM)){
  PITT =  pitt[complete.cases(pitt),c(protein,adjustVar,outcome)]
  RMM = RM[complete.cases(RM),c(protein,adjustVar,outcome)]
  
  p = (sample(nrow(PITT), nrow(PITT)*ratio))
  Rm = (sample(nrow(RMM), nrow(RMM)*ratio))
  
  p1 = PITT[p,]
  rm1 = RMM[Rm,]
  
  p2 = PITT[-p,]
  rm2 = RMM[-Rm,]
  
  train <-rbind(p1,rm1)
  test <-rbind(p2,rm2)
  }else
  {
    pitt =  All_patients[complete.cases(All_patients),c(protein,adjustVar,outcome)]
    dt = (sample(nrow(pitt), nrow(pitt)*ratio))
    train<-pitt[dt,]
    test<-pitt[-dt,]
  } 
  pitt = rbind(train,test)
  y_train = as.numeric(unlist(train[,(names(train) %in% outcome)]))
  x <- data.matrix(train[,!(names(train) %in% outcome)])
  y_test = as.numeric(unlist(test[,(names(test) %in% outcome)]))
  x_test <- data.matrix(test[,!(names(test) %in% outcome)])
  xgb.train.data <- xgb.DMatrix(data = x, label = y_train,missing = NA)
  param <- list(objective = "binary:logistic", base_score = 0.5)
  all_x <- data.matrix(pitt[,!(names(pitt) %in% outcome)])
  all_y = as.numeric(unlist(pitt[,(names(pitt) %in% outcome)]))
  xgb.train.data2 <- xgb.DMatrix(data = all_x, label = all_y,missing = NA)

  cv <- xgb.cv(data = xgb.train.data2,  nrounds = 1500, nthread = 20, nfold = 5, metrics = list("auc"),max_depth = 20,early_stopping_rounds = 100, eta = 1, objective = "binary:logistic")
  bestIte = cv$best_iteration
  
  best_model <- xgboost(param =param,  data = xgb.train.data, nrounds=bestIte)
  pred_train <- predict(best_model, x, type="prob")
  new_pred_xgb_train = as.data.frame(ifelse(pred_train >= cutoff, 1, 0))
  pred <- predict(best_model, x_test, type="prob")
  new_pred_xgb = as.data.frame(ifelse(pred >= cutoff, 1, 0))
  data_xgb = cbind(test[,c(outcome)], new_pred_xgb)
  names(data_xgb) = c("actual", "pred")
  xtab_xgb = table(data_xgb$actual, data_xgb$pred)
    
  cm_xgb = confusionMatrix(xtab_xgb, mode = "everything", positive="1")
  F1Score = round(as.data.frame(cm_xgb$byClass[c(1,2:5,7)]),2)
  names(F1Score)= c("Coefficient")

  # Model Performance Statistics
  pred_val <-prediction(pred, y_test)
  auc = roc(y_test~ pred)
  ci = as.numeric(ci.auc(auc))
  auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
  names(auc1) = c("Coefficient")
  row.names(auc1) = c("Combined")

  # Calculating Area under Curve
  perf_val <- performance(pred_val,"auc")
  perf_val
  # Calculating True Positive and False Positive Rate
  perf_1 <- performance(pred_val, "tpr", "fpr")
  auc11 = round(perf_val@y.values[[1]],2)
  # Plot the ROC curve
  plot(perf_1, col = "green", lwd = 1.5)
  xgb_coef = rbind(F1Score,auc1)
  feature = xgb.importance(model = best_model)
  return (c(performance = xgb_coef, feature = feature, perf = perf_1, confusionMat = cm_xgb, preds= as.data.frame(pred),preds_train = as.data.frame(pred_train) ))

}
```

## PDDS
```{r}
seed=2042
outcome = c("pdds_cat")
cutoff = 0.4
ratio = .8
adjustVar_null = NULL
protein_null = NULL

xgb_PDDS_combine = xgb_model(seed,ratio,pitt,RM,protein,adjustVar,outcome,cutoff)
preds_xgb = xgb_PDDS_combine$preds.pred
preds_xgb_train = xgb_PDDS_combine$preds_train.pred_train
auc11 = as.numeric(substr(xgb_PDDS_combine$performance.Coefficient[7],1,4))
perf = xgb_PDDS_combine$perf
xgb_PDDS_combine_perf = as.data.frame((xgb_PDDS_combine$performance.Coefficient))
row.names(xgb_PDDS_combine_perf) = c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI")
names(xgb_PDDS_combine_perf) = c("Coef")
xgb_PDDS_Feature = xgb_PDDS_combine$feature.Feature

xgb_PDDS_protein = xgb_model(seed,ratio,pitt,RM,protein,adjustVar_null,outcome,cutoff)
auc33 = as.numeric(substr(xgb_PDDS_protein$performance.Coefficient[7],1,4))
perf3 = xgb_PDDS_protein$perf
xgb_PDDS_protein_perf = as.data.frame(xgb_PDDS_protein$performance.Coefficient)
row.names(xgb_PDDS_protein_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_protein")
names(xgb_PDDS_protein_perf) = c("Coef")
  
xgb_PDDS_clinical = xgb_model(seed,ratio,pitt,RM,protein_null,adjustVar,outcome,cutoff)
perf2 = xgb_PDDS_clinical$perf
auc22 = as.numeric(substr(xgb_PDDS_clinical$performance.Coefficient[7],1,4))
xgb_PDDS_clinical_perf = as.data.frame(xgb_PDDS_clinical$performance.Coefficient)
row.names(xgb_PDDS_clinical_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_Clinical")
names(xgb_PDDS_clinical_perf) = c("Coef")

xgb_PDDS_total = rbind(xgb_PDDS_combine_perf,xgb_PDDS_protein_perf,xgb_PDDS_clinical_perf)
svg("xgb_PDDS_2042.svg",width = 7, height = 5.2)
{plot(perf3,colorize=FALSE, col="#0066CC")
plot(perf2,colorize=FALSE, col="#990033",add = T) 
plot(perf,colorize=FALSE, col="#FF9900",add = T) 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend(0.6,0.45, legend = c(paste("Serum Biomarker Profile (AUC =", auc33, ")"),
                          paste("Clinical Profile (AUC = ", auc22, ")"),
                paste("Combined Profile (AUC = ", auc11, ")")),lty=c(1,1),lwd=c(1,1),col=c('#0066CC','#990033','#FF9900'),cex=.6)
}
dev.off()
```
## PROMIS
```{r}
seed = 23
outcome = c("PROMIS_Bi")
cutoff = 0.55
ratio = .8

xgb_PROMIS_combine = xgb_model(seed,ratio,All_patients,RM_null,protein,adjustVar.PROMIS,outcome,cutoff)
auc11 = as.numeric(substr(xgb_PROMIS_combine$performance.Coefficient[7],1,4))
perf = xgb_PROMIS_combine$perf
xgb_PROMIS_combine_perf = as.data.frame((xgb_PROMIS_combine$performance.Coefficient))
row.names(xgb_PROMIS_combine_perf) = c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI")
names(xgb_PROMIS_combine_perf) = c("Coef")
xgb_PROMIS_Feature = xgb_PROMIS_combine$feature.Feature


preds_xgb_PROMIS = xgb_PROMIS_combine$preds.pred
preds_xgb__PROMIS_train = xgb_PROMIS_combine$preds_train.pred_train

xgb_PROMIS_protein = xgb_model(seed,ratio,All_patients,RM_null,protein,adjustVar_null,outcome,cutoff)
auc33 = as.numeric(substr(xgb_PROMIS_protein$performance.Coefficient[7],1,4))
perf3 = xgb_PROMIS_protein$perf
xgb_PROMIS_protein_perf = as.data.frame(xgb_PROMIS_protein$performance.Coefficient)
row.names(xgb_PROMIS_protein_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_protein")
names(xgb_PROMIS_protein_perf) = c("Coef")
  
xgb_PROMIS_clinical = xgb_model(seed,ratio,All_patients,RM_null,protein_null,adjustVar.PROMIS,outcome,cutoff)
perf2 = xgb_PROMIS_clinical$perf
auc22 = as.numeric(substr(xgb_PROMIS_clinical$performance.Coefficient[7],1,4))
xgb_PROMIS_clinical_perf = as.data.frame(xgb_PROMIS_clinical$performance.Coefficient)
row.names(xgb_PROMIS_clinical_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_Clinical")
names(xgb_PROMIS_clinical_perf) = c("Coef")

xgb_PROMIS_total = rbind(xgb_PROMIS_combine_perf,xgb_PROMIS_protein_perf,xgb_PROMIS_clinical_perf)
svg("xgb_PROMIS_23.svg",width = 7, height = 5.2)
{plot(perf3,colorize=FALSE, col="#0066CC")
plot(perf2,colorize=FALSE, col="#990033",add = T) 
plot(perf,colorize=FALSE, col="#FF9900",add = T) 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend(0.6,0.45, legend = c(paste("Serum Biomarker Profile (AUC =", auc33, ")"),
                          paste("Clinical Profile (AUC = ", auc22, ")"),
                paste("Combined Profile (AUC = ", auc11, ")")),lty=c(1,1),lwd=c(1,1),col=c('#0066CC','#990033','#FF9900'),cex=.6)
}
dev.off()
    
```
# Random Forest (RF)
```{r}

rf_model = function(seed,ratio,pitt,RM,protein,adjustVar,outcome,cutoff){
  
  
  set.seed(seed)
  if (!is.null(RM)){
  PITT =  pitt[complete.cases(pitt),c(protein,adjustVar,outcome)]
  RMM = RM[complete.cases(RM),c(protein,adjustVar,outcome)]
  
  p = (sample(nrow(PITT), nrow(PITT)*ratio))
  Rm = (sample(nrow(RMM), nrow(RMM)*ratio))
  
  p1 = PITT[p,]
  rm1 = RMM[Rm,]
  
  p2 = PITT[-p,]
  rm2 = RMM[-Rm,]
  
  train <-rbind(p1,rm1)
  test <-rbind(p2,rm2)
  }else
  {
    pitt =  All_patients[complete.cases(All_patients),c(protein,adjustVar,outcome)]
    dt = (sample(nrow(pitt), nrow(pitt)*ratio))
    train<-pitt[dt,]
    test<-pitt[-dt,]
  } 
  
  y_train = as.numeric(unlist(train[,(names(train) %in% outcome)]))
  x <- data.matrix(train[,!(names(train) %in% outcome)])
  y_test = as.numeric(unlist(test[,(names(test) %in% outcome)]))
  x_test <- data.matrix(test[,!(names(test) %in% outcome)])

  if (outcome == "pdds_cat"){
    train$pdds_cat = as.factor(train$pdds_cat)
    rf <- randomForest( pdds_cat ~ .,  data=train,ntree = 1000)
  } else{
    train$PROMIS_Bi = as.factor(train$PROMIS_Bi)
    rf <- randomForest( PROMIS_Bi ~ .,  data=train,ntree = 1000)

  }

 
  pred <- predict(rf, x_test, type="prob")[,2]
  new_pred_rf = as.data.frame(ifelse(pred >= cutoff, 1, 0))
  pred_train <- predict(rf, x, type="prob")[,2]
  new_pred_rf_train = as.data.frame(ifelse(pred_train >= cutoff, 1, 0))
  data_rf = cbind(test[,c(outcome)], new_pred_rf)
  names(data_rf) = c("actual", "pred")
  xtab_rf = table(data_rf$actual, data_rf$pred)
    
  cm_rf = confusionMatrix(xtab_rf, mode = "everything", positive="1")
  F1Score = round(as.data.frame(cm_rf$byClass[c(1,2:5,7)]),2)
  names(F1Score)= c("Coefficient")

  # Model Performance Statistics
  pred_val <-prediction(pred, y_test)
  auc = roc(as.factor(y_test)~ pred)
  ci = as.numeric(ci.auc(auc))
  auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
  names(auc1) = c("Coefficient")
  row.names(auc1) = c("Combined")

  # Calculating Area under Curve
  perf_val <- performance(pred_val,"auc")
  perf_val
  # Calculating True Positive and False Positive Rate
  perf_1 <- performance(pred_val, "tpr", "fpr")
  auc11 = round(perf_val@y.values[[1]],2)
  # Plot the ROC curve
  plot(perf_1, col = "green", lwd = 1.5)
  rf_coef = rbind(F1Score,auc1)
  feature = as.data.frame(importance(rf))
  feature$names <- row.names(feature)
  fea_names = attach_name(protein,adjustVar)
  svg(paste0("rf_",outcome,"_",fea_names,seed,".svg"),width = 4, height = 6.5 )
  varImpPlot(rf)
  dev.off()

  return (c(performance = rf_coef, feature = feature, perf = perf_1, confusionMat = cm_rf, preds = as.data.frame(pred), preds_train = as.data.frame(pred_train)))

}
```

## PDDS
```{r}
seed=2042
outcome = c("pdds_cat")
cutoff = 0.33
ratio = .8
rf_PDDS_combine = rf_model(seed,ratio,pitt,RM,protein,adjustVar,outcome,cutoff)
```
 
 
```{r}
preds_rf = rf_PDDS_combine$preds.pred
preds_rf_train = rf_PDDS_combine$preds_train.pred_train
auc11 = as.numeric(substr(rf_PDDS_combine$performance.Coefficient[7],1,4))
perf = rf_PDDS_combine$perf
rf_PDDS_combine_perf = as.data.frame((rf_PDDS_combine$performance.Coefficient))
row.names(rf_PDDS_combine_perf) = c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI")
names(rf_PDDS_combine_perf) = c("Coef")
rf_PDDS_Feature = as.data.frame(rf_PDDS_combine$feature.names)
rf_PDDS_Feature$MeanDecreaseGini = rf_PDDS_combine$feature.MeanDecreaseGini
rf_PDDS_Feature <- rf_PDDS_Feature[order(-rf_PDDS_Feature$MeanDecreaseGini),]

rf_PDDS_protein = rf_model(seed,ratio,pitt,RM,protein,adjustVar_null,outcome,cutoff)
auc33 = as.numeric(substr(rf_PDDS_protein$performance.Coefficient[7],1,4))
perf3 = rf_PDDS_protein$perf
rf_PDDS_protein_perf = as.data.frame(rf_PDDS_protein$performance.Coefficient)
row.names(rf_PDDS_protein_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_protein")
names(rf_PDDS_protein_perf) = c("Coef")
  
rf_PDDS_clinical = rf_model(seed,ratio,pitt,RM,protein_null,adjustVar,outcome,cutoff)
perf2 = rf_PDDS_clinical$perf
auc22 = as.numeric(substr(rf_PDDS_clinical$performance.Coefficient[7],1,4))
rf_PDDS_clinical_perf = as.data.frame(rf_PDDS_clinical$performance.Coefficient)
row.names(rf_PDDS_clinical_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_Clinical")
names(rf_PDDS_clinical_perf) = c("Coef")

rf_PDDS_total = rbind(rf_PDDS_combine_perf,rf_PDDS_protein_perf,rf_PDDS_clinical_perf)
svg(paste0("rf_PDDS_",seed,".svg"),width = 7, height = 5.2)
{plot(perf3,colorize=FALSE, col="#0066CC")
plot(perf2,colorize=FALSE, col="#990033",add = T) 
plot(perf,colorize=FALSE, col="#FF9900",add = T) 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend(0.6,0.45, legend = c(paste("Serum Biomarker Profile (AUC =", auc33, ")"),
                          paste("Clinical Profile (AUC = ", auc22, ")"),
                paste("Combined Profile (AUC = ", auc11, ")")),lty=c(1,1),lwd=c(1,1),col=c('#0066CC','#990033','#FF9900'),cex=.6)
}
dev.off()
    
```

## PROMIS_BI
```{r}
seed=23
outcome = c("PROMIS_Bi")
cutoff = 0.6
ratio = .8
```
 
 
```{r}

rf_PROMIS_combine = rf_model(seed,ratio,All_patients,RM_null,protein,adjustVar.PROMIS,outcome,cutoff)
auc11 = as.numeric(substr(rf_PROMIS_combine$performance.Coefficient[7],1,4))
perf = rf_PROMIS_combine$perf
rf_PROMIS_combine_perf = as.data.frame((rf_PROMIS_combine$performance.Coefficient))
row.names(rf_PROMIS_combine_perf) = c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI")
names(rf_PROMIS_combine_perf) = c("Coef")

preds_rf_PROMIS = rf_PROMIS_combine$preds.pred
preds_rf_PROMIS_train = rf_PROMIS_combine$preds_train.pred_train
  
rf_PROMIS_Feature = as.data.frame(rf_PROMIS_combine$feature.names)
rf_PROMIS_Feature$MeanDecreaseGini = rf_PROMIS_combine$feature.MeanDecreaseGini
rf_PROMIS_Feature <- rf_PROMIS_Feature[order(-rf_PROMIS_Feature$MeanDecreaseGini),]

rf_PROMIS_protein = rf_model(seed,ratio,All_patients,RM_null,protein,adjustVar_null,outcome,cutoff)
auc33 = as.numeric(substr(rf_PROMIS_protein$performance.Coefficient[7],1,4))
perf3 = rf_PROMIS_protein$perf
rf_PROMIS_protein_perf = as.data.frame(rf_PROMIS_protein$performance.Coefficient)
row.names(rf_PROMIS_protein_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_protein")
names(rf_PROMIS_protein_perf) = c("Coef")
  
rf_PROMIS_clinical = rf_model(seed,ratio,All_patients,RM_null,protein_null,adjustVar.PROMIS,outcome,cutoff)
perf2 = rf_PROMIS_clinical$perf
auc22 = as.numeric(substr(rf_PROMIS_clinical$performance.Coefficient[7],1,4))
rf_PROMIS_clinical_perf = as.data.frame(rf_PROMIS_clinical$performance.Coefficient)
row.names(rf_PROMIS_clinical_perf) =c("Sensitivity","Specificity", "Pos Pred Value","Neg Pred Value","Precision","F1","CI_Clinical")
names(rf_PROMIS_clinical_perf) = c("Coef")

rf_PROMIS_total = rbind(rf_PROMIS_combine_perf,rf_PROMIS_protein_perf,rf_PROMIS_clinical_perf)
svg(paste0("rf_PROMIS_",seed,".svg"),width = 7, height = 5.2)
{plot(perf3,colorize=FALSE, col="#0066CC")
plot(perf2,colorize=FALSE, col="#990033",add = T) 
plot(perf,colorize=FALSE, col="#FF9900",add = T) 
lines(c(0,1),c(0,1),col = "gray", lty = 4 )
legend(0.6,0.45, legend = c(paste("Serum Biomarker Profile (AUC =", auc33, ")"),
                          paste("Clinical Profile (AUC = ", auc22, ")"),
                paste("Combined Profile (AUC = ", auc11, ")")),lty=c(1,1),lwd=c(1,1),col=c('#0066CC','#990033','#FF9900'),cex=.6)
}
dev.off()
    
```


# PDDS: ensemble machine learning 

```{r}
set.seed(2042)
outcome = c("pdds_cat")
ratio = 0.8
PITT =  pitt[complete.cases(pitt),c(protein,adjustVar,outcome)]
RMM = RM[complete.cases(RM),c(protein,adjustVar,outcome)]

p = (sample(nrow(PITT), nrow(PITT)*ratio))
Rm = (sample(nrow(RMM), nrow(RMM)*ratio))

p1 = PITT[p,]
rm1 = RMM[Rm,]

p2 = PITT[-p,]
rm2 = RMM[-Rm,]

train <-rbind(p1,rm1)
test <-rbind(p2,rm2)
pdds_train = as.factor(train$pdds_cat)
pdds_test =as.factor(test$pdds_cat)
Ensem_train = data.frame(preds_xgb_train,preds_lasso_train,pred_SVM_train,preds_rf_train,pdds_train)
Ensem_test = data.frame(preds_xgb,preds_lasso_test,pred_SVM,preds_rf,pdds_test)
ensemble_names = c("xgb","lasso","svm","rf")
outcome = ("pdds_cat")
names(Ensem_train) = c(ensemble_names,outcome)
names(Ensem_test) = c(ensemble_names,outcome)

y_train = as.numeric(as.character(unlist(Ensem_train[,(names(Ensem_train) %in% outcome)])))
x <- data.matrix(Ensem_train[,!(names(Ensem_train) %in% outcome)])
y_test = as.numeric(as.character(unlist(Ensem_test[,(names(Ensem_test) %in% outcome)])))
x_test <- data.matrix(Ensem_test[,!(names(Ensem_test) %in% outcome)])
```

## RF

```{r}
rf <- randomForest( pdds_cat ~ .,  data=Ensem_train,ntree = 1000)
    
cutoff = 0.33
ratio = .8
  pred <- predict(rf, x_test, type="prob")[,2]
  new_pred_rf = as.data.frame(ifelse(pred >= cutoff, 1, 0))
  pred_train <- predict(rf, x, type="prob")[,2]
  new_pred_rf_train = as.data.frame(ifelse(pred_train >= cutoff, 1, 0))
  data_rf = cbind(test[,c(outcome)], new_pred_rf)
  names(data_rf) = c("actual", "pred")
  xtab_rf = table(data_rf$actual, data_rf$pred)
    
  cm_rf = confusionMatrix(xtab_rf, mode = "everything", positive="1")
  cm_rf
  F1Score = round(as.data.frame(cm_rf$byClass[c(1,2:5,7)]),2)
  names(F1Score)= c("Coefficient")
  # Model Performance Statistics
  pred_val <-prediction(pred, y_test)
  auc = roc(as.factor(y_test)~ pred)
  ci = as.numeric(ci.auc(auc))
  auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
  names(auc1) = c("Coefficient")
  row.names(auc1) = c("Combined")
  F1Score[nrow(F1Score)+1,] = auc1
  # Calculating Area under Curve
  perf_val <- performance(pred_val,"auc")
  perf_val
  # Calculating True Positive and False Positive Rate
  perf_1 <- performance(pred_val, "tpr", "fpr")
  auc11 = round(perf_val@y.values[[1]],2)
  print(paste("ensemble learning for RF:", auc11,"(original: 0.79)"))
  # Plot the ROC curve
  # plot(perf_1, col = "green", lwd = 1.5)
  write.csv(F1Score,paste0( file = "PDDS_ensemble_rf",auc11,".csv"), row.names = T)

```
## LASSO

```{r}
seed = 2042
ratio = 0.8
outcome = c("pdds_cat")
cutoff= 0.4

lambdas <- 10^seq(2, -3, length = 500)
cv_model <- cv.glmnet(x, as.numeric(as.character(y_train)), alpha = 1,lambda = lambdas, standardize = TRUE,nfolds = 10, type = "auc")

best_lambda <- cv_model$lambda.min
best_model <- glmnet(x, as.numeric(as.character(y_train)), alpha = 1, lambda = best_lambda)

predictions_test <- predict(best_model, s = best_lambda, newx = x_test)

new_pred_lasso = as.data.frame(ifelse(predictions_test >= cutoff, 1, 0))

data_lasso = cbind(test[,c(outcome)], new_pred_lasso)
names(data_lasso) = c("actual", "pred")
xtab_lasso = table(data_lasso$actual, data_lasso$pred)

cm_lasso = confusionMatrix(xtab_lasso, mode = "everything", positive="1")
cm_lasso
F1Score = round(as.data.frame(cm_lasso$byClass[c(1,2:5,7)]),2)
names(F1Score)= c("Coefficient")
test$lasso.prob <- predict(best_model,type="response",newx = x_test, s = 'best_lambda')
pred <- prediction(test$lasso.prob, test[, c(outcome)])
auc = roc(y_test~ predictions_test)
ci = as.numeric(ci.auc(auc))
auc12 = (round(ci[2],2))
auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")
F1Score[nrow(F1Score)+1,] = auc1
  
```

## XGBoost
```{r}
cutoff = 0.4
y_train = as.character(unlist(Ensem_train[,(names(Ensem_train) %in% outcome)]))
combine = rbind(Ensem_test,Ensem_train)
xgb.train.data <- xgb.DMatrix(data = x, label = as.numeric(y_train),missing = NA)
param <- list(objective = "binary:logistic", base_score = 0.5)
all_x <- data.matrix(combine[,!(names(combine) %in% outcome)])
all_y = as.character(unlist(combine[,(names(combine) %in% outcome)]))
xgb.train.data2 <- xgb.DMatrix(data = all_x, label = as.numeric(all_y),missing = NA)

cv <- xgb.cv(data = xgb.train.data2,  nrounds = 1500, nthread = 20, nfold = 5, metrics = list("auc"),max_depth = 20,early_stopping_rounds = 100, eta = 1, objective = "binary:logistic")
bestIte = cv$best_iteration

best_model <- xgboost(param =param,  data = xgb.train.data, nrounds=bestIte)
pred <- predict(best_model, x_test, type="prob")
new_pred_xgb = as.data.frame(ifelse(pred >= cutoff, 1, 0))
data_xgb = cbind(test[,c(outcome)], new_pred_xgb)
names(data_xgb) = c("actual", "pred")
xtab_xgb = table(data_xgb$actual, data_xgb$pred)
  
cm_xgb = confusionMatrix(xtab_xgb, mode = "everything", positive="1")
cm_xgb
F1Score = round(as.data.frame(cm_xgb$byClass[c(1,2:5,7)]),2)


# Model Performance Statistics
pred_val <-prediction(pred, y_test)
auc = roc(y_test~ pred)
ci = as.numeric(ci.auc(auc))

auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")
F1Score[nrow(F1Score)+1,] = auc1

auc13 = (round(ci[2],2))
```

## SVM
```{r}
seed = 2042
set.seed(seed)
model_svm = svm(pdds_cat ~ .,
               data = Ensem_train,
               cost = 10,scale = T,
               kernel = 'radial')
cutoff = 0.25
class1.svm.model <- svm(pdds_cat ~ ., data = Ensem_train,cost=0.1, cross=10,type="C-classification",kernel="radial",na.action=na.omit)

tmodel=tune(svm,pdds_cat ~., data=Ensem_train,
ranges=list(cost = c(0.001, 0.01, 0.1, 1,5,10,15)))
best_model = tmodel$best.model
pred <- predict(class1.svm.model, x_test, type="response")
# new_pred_svm = as.data.frame(ifelse(pred >= cutoff, 1, 0))  
data_svm = cbind(test[,c(outcome)], pred)
names(data_svm) = c("actual", "pred")
xtab_svm = table(data_svm$actual, data_svm$pred)
  

new_pred_svm <- predict(best_model, x_test, type="prob")
# new_pred_svm = as.data.frame(ifelse(pred >= cutoff, 1, 0))  

new_pred_svm_train <- predict(best_model, x, type="prob")
# new_pred_svm_train = as.data.frame(ifelse(pred_train >= cutoff, 1, 0))

data_svm = cbind(test[,c(outcome)], new_pred_svm)
names(data_svm) = c("actual", "pred")
xtab_svm = table(data_svm$actual, data_svm$pred)
  
cm_svm = confusionMatrix(xtab_svm, mode = "everything", positive="1")
F1Score = round(as.data.frame(cm_svm$byClass[c(1,2:5,7)]),2)
names(F1Score)= c("Coefficient")

# Model Performance Statistics
pred_val <-prediction(as.numeric(new_pred_svm), y_test)
auc = roc(y_test~ as.numeric(new_pred_svm))
ci = as.numeric(ci.auc(auc))
auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")

cm_svm = confusionMatrix(xtab_svm, mode = "everything", positive="1")
F1Score = round(as.data.frame(cm_svm$byClass[c(1,2:5,7)]),2)
names(F1Score)= c("Coefficient")
auc = roc(y_test~ as.numeric(new_pred_svm))
ci = as.numeric(ci.auc(auc))
auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")
F1Score[nrow(F1Score)+1,] = auc1
auc44 = paste(round(ci[2],2))

```

# PROMIS Ensemble 


```{r}
set.seed(23)
ratio = .8
outcome = c("PROMIS_Bi")
PROMIS_allpatients =  All_patients[complete.cases(All_patients),c(protein,adjustVar.PROMIS,outcome)]
dt = (sample(nrow(PROMIS_allpatients), nrow(PROMIS_allpatients)*ratio))
train<-PROMIS_allpatients[dt,]
test<-PROMIS_allpatients[-dt,]

PROMIS_train = as.factor(train$PROMIS_Bi)
PROMIS_test =as.factor(test$PROMIS_Bi)
Ensem_train = data.frame(preds_xgb__PROMIS_train,preds_lasso_promis_train,pred_SVM_PROMIS_train,preds_rf_PROMIS_train,PROMIS_train)
Ensem_test = data.frame(preds_xgb_PROMIS,preds_lasso_promis,pred_SVM_PROMIS,preds_rf_PROMIS,PROMIS_test)
ensemble_names = c("xgb","lasso","svm","rf")

names(Ensem_train) = c(ensemble_names,outcome)
names(Ensem_test) = c(ensemble_names,outcome)

y_train = as.factor(as.character(unlist(Ensem_train[,(names(Ensem_train) %in% outcome)])))
x <- data.matrix(Ensem_train[,!(names(Ensem_train) %in% outcome)])
y_test = as.numeric(as.character(unlist(Ensem_test[,(names(Ensem_test) %in% outcome)])))
x_test <- data.matrix(Ensem_test[,!(names(Ensem_test) %in% outcome)])
```

## XGBoost
```{r}
seed = 23

cutoff = 0.55
y_train = as.character(unlist(Ensem_train[,(names(Ensem_train) %in% outcome)]))
combine = rbind(Ensem_test,Ensem_train)
xgb.train.data <- xgb.DMatrix(data = x, label = as.numeric(y_train),missing = NA)
param <- list(objective = "binary:logistic", base_score = 0.5)
all_x <- data.matrix(combine[,!(names(combine) %in% outcome)])
all_y = as.character(unlist(combine[,(names(combine) %in% outcome)]))
xgb.train.data2 <- xgb.DMatrix(data = all_x, label = as.numeric(all_y),missing = NA)

cv <- xgb.cv(data = xgb.train.data2,  nrounds = 1500, nthread = 20, nfold = 5, metrics = list("auc"),max_depth = 20,early_stopping_rounds = 100, eta = 1, objective = "binary:logistic")
bestIte = cv$best_iteration

best_model <- xgboost(param =param,  data = xgb.train.data, nrounds=bestIte)
pred <- predict(best_model, x_test, type="prob")
new_pred_xgb = as.data.frame(ifelse(pred >= cutoff, 1, 0))
data_xgb = cbind(test[,c(outcome)], new_pred_xgb)
names(data_xgb) = c("actual", "pred")
xtab_xgb = table(data_xgb$actual, data_xgb$pred)
  
cm_xgb = confusionMatrix(xtab_xgb, mode = "everything", positive="1")
cm_xgb

  # Model Performance Statistics
pred_val <-prediction(pred, y_test)
F1Score = round(as.data.frame(cm_xgb$byClass[c(1,2:5,7)]),2)
auc = roc(y_test~ pred)
ci = as.numeric(ci.auc(auc))
auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")
F1Score[nrow(F1Score)+1,] = auc1
auc3pr = (round(ci[2],2))


```

## RF 
```{r}
rf <- randomForest( PROMIS_Bi ~ .,  data=Ensem_train,ntree = 1000)
    
cutoff = 0.6

pred <- predict(rf, x_test, type="prob")[,2]
new_pred_rf = as.data.frame(ifelse(pred >= cutoff, 1, 0))
pred_train <- predict(rf, x, type="prob")[,2]
new_pred_rf_train = as.data.frame(ifelse(pred_train >= cutoff, 1, 0))
data_rf = cbind(Ensem_test[,c(outcome)], new_pred_rf)
names(data_rf) = c("actual", "pred")
xtab_rf = table(data_rf$actual, data_rf$pred)
  
cm_rf = confusionMatrix(xtab_rf, mode = "everything", positive="1")
cm_rf

F1Score = round(as.data.frame(cm_rf$byClass[c(1,2:5,7)]),2)
names(F1Score)= c("Coefficient")
# Model Performance Statistics
pred_val <-prediction(pred, y_test)
auc = roc(y_test~ pred)
ci = as.numeric(ci.auc(auc))
auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")
F1Score[nrow(F1Score)+1,] = auc1

perf_val <- performance(pred_val,"auc")
auc1pr = round(perf_val@y.values[[1]],2)
print(paste0("PROMIS RF:",auc1pr,"(original: 0.83)"))
write.csv(F1Score, paste0(file = "PROMIS_ensemble_rf",auc1pr,".csv"), row.names = T)

```
## LASSO

```{r}
seed = 23
ratio = 0.6
run_comb = F
outcome = c("PROMIS_Bi")
cutoff= .6

lambdas <- 10^seq(2, -3, length = 500)
cv_model <- cv.glmnet(x, as.numeric(as.character(y_train)), alpha = 1,lambda = lambdas, standardize = TRUE,nfolds = 10, type = "auc")

best_lambda <- cv_model$lambda.min
best_model <- glmnet(x, as.numeric(as.character(y_train)), alpha = 1, lambda = best_lambda)

predictions_test <- predict(best_model, s = best_lambda, newx = x_test)

new_pred_lasso = as.data.frame(ifelse(predictions_test >= cutoff, 1, 0))

data_lasso = cbind(test[,c(outcome)], new_pred_lasso)
names(data_lasso) = c("actual", "pred")
xtab_lasso = table(data_lasso$actual, data_lasso$pred)

cm_lasso = confusionMatrix(xtab_lasso, mode = "everything", positive="1")
cm_lasso
F1Score = round(as.data.frame(cm_lasso$byClass[c(1,2:5,7)]),2)
names(F1Score)= c("Coefficient")

Ensem_test$lasso.prob <- predict(best_model,type="response",newx = x_test, s = 'best_lambda')
pred <- prediction(Ensem_test$lasso.prob, Ensem_test[, c(outcome)])
auc = roc(y_test~ predictions_test)
ci = as.numeric(ci.auc(auc))
auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")
F1Score[nrow(F1Score)+1,] = auc1
auc2 = (round(ci[2],2))

```


## SVM
```{r}
seed = 23

set.seed(seed)
model_svm = svm(PROMIS_Bi ~ .,
               data = Ensem_train,
               cost = 10,scale = T,
               kernel = 'radial')



  tmodel=tune(svm,PROMIS_Bi ~., data=Ensem_train,
ranges=list(cost = c(0.001, 0.01, 0.1, 1,5,10,15)))
best_model = tmodel$best.model
new_pred_svm <- predict(best_model, x_test, type="prob")

new_pred_svm_train <- predict(best_model, x, type="prob")
data_svm = cbind(test[,c(outcome)], new_pred_svm)
names(data_svm) = c("actual", "pred")
xtab_svm = table(data_svm$actual, data_svm$pred)
  
cm_svm = confusionMatrix(xtab_svm, mode = "everything", positive="1")
F1Score = round(as.data.frame(cm_svm$byClass[c(1,2:5,7)]),2)
names(F1Score)= c("Coefficient")

# Model Performance Statistics
pred_val <-prediction(as.numeric(new_pred_svm), y_test)
auc = roc(y_test~ as.numeric(new_pred_svm))
ci = as.numeric(ci.auc(auc))
auc1 = as.data.frame(c(paste(round(ci[2],2),"(",round(ci[1],2),",",round(ci[3],2),")")))
names(auc1) = c("Coefficient")
row.names(auc1) = c("Combined")


F1Score[nrow(F1Score)+1,] = auc1
auc4Promis = paste(round(ci[2],2))
write.csv(F1Score, file = paste0("PROMIS_ensemble_SVM",auc4Promis,".csv"), row.names = T)

  
```

